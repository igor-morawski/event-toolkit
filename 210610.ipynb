{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1daed81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook is from Prophesee toolbox ;)\n",
    "# always move notebook to .. \n",
    "import numpy as np\n",
    "from prophesee.src.io.psee_loader import PSEELoader\n",
    "from prophesee.src.io.box_loading import reformat_boxes\n",
    "from settings.data import settings\n",
    "import os.path as op\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59083a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSEELoader:\n",
      "-----------\n",
      "Event Type: Event2D\n",
      "Event Size: 8 bytes\n",
      "Event Count: 63200927\n",
      "Duration: 59.999998999999995 s \n",
      "-----------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "59999999"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video = PSEELoader(op.join(settings['automotive_path'],\"train_a\",\"17-03-30_12-53-58_1098500000_1158500000_td.dat\"))\n",
    "print(video)  # show some metadata\n",
    "video.event_count()  # number of events in the file\n",
    "video.total_time()  # duration of the file in mus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36f2154",
   "metadata": {},
   "source": [
    "# Voxels\n",
    "Convert events to voxels.\n",
    "\n",
    "References:\n",
    "\n",
    "https://openaccess.thecvf.com/content_CVPR_2019/papers/Zhu_Unsupervised_Event-Based_Learning_of_Optical_Flow_Depth_and_Egomotion_CVPR_2019_paper.pdf\n",
    "\n",
    "https://github.com/alexzzhu/EventGAN/blob/master/EventGAN/utils/event_utils.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e4abb0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "torch.Size([10, 240, 304])\n"
     ]
    }
   ],
   "source": [
    "def us_to_s(us):\n",
    "    return us/1000000\n",
    "\n",
    "def us_to_ms(us):\n",
    "    return us/1000\n",
    "\n",
    "def s_to_us(us):\n",
    "    return us*1000000\n",
    "\n",
    "def ms_to_us(us):\n",
    "    return us*1000\n",
    "\n",
    "def calc_floor_ceil_delta(x): \n",
    "    # github.com/alexzzhu/EventGAN\n",
    "    x_fl = torch.floor(x + 1e-8)\n",
    "    x_ce = torch.ceil(x - 1e-8)\n",
    "    x_ce_fake = torch.floor(x) + 1\n",
    "\n",
    "    dx_ce = x - x_fl\n",
    "    dx_fl = x_ce_fake - x\n",
    "    return [x_fl.long(), dx_fl], [x_ce.long(), dx_ce]\n",
    "\n",
    "def create_update(x, y, t, dt, p, vol_size):\n",
    "    # github.com/alexzzhu/EventGAN\n",
    "    assert (x>=0).byte().all() and (x<vol_size[2]).byte().all()\n",
    "    assert (y>=0).byte().all() and (y<vol_size[1]).byte().all()\n",
    "    assert (t>=0).byte().all() and (t<vol_size[0] // 2).byte().all()\n",
    "\n",
    "    vol_mul = torch.where(p < 0,\n",
    "                          torch.ones(p.shape, dtype=torch.long) * vol_size[0] // 2,\n",
    "                          torch.zeros(p.shape, dtype=torch.long))\n",
    "\n",
    "    inds = (vol_size[1]*vol_size[2]) * (t + vol_mul)\\\n",
    "         + (vol_size[2])*y\\\n",
    "         + x\n",
    "\n",
    "    vals = dt\n",
    "\n",
    "    return inds, vals\n",
    "\n",
    "def events_to_voxel(events, bins, height, width, device=torch.device('cuda:0')):\n",
    "    # github.com/alexzzhu/EventGAN\n",
    "    vol_size = [2*bins, height, width]\n",
    "    npts = events.shape[0]\n",
    "    volume = torch.zeros(*vol_size).cpu() # TODO: confirm\n",
    "    \n",
    "    x = torch.Tensor(events['x'].astype('long')).cpu().long()\n",
    "    y = torch.Tensor(events['y'].astype('long')).cpu().long()\n",
    "    t = torch.Tensor(events['t'].astype('long')).cpu().long()\n",
    "    p = torch.Tensor(events['p'].astype('long')).cpu().long()\n",
    "    \n",
    "    t_min = t.min()\n",
    "    t_max = t.max()\n",
    "    t_scaled = (t-t_min) * ((vol_size[0] // 2-1) / (t_max-t_min))\n",
    "    \n",
    "    ts_fl, ts_ce = calc_floor_ceil_delta(t_scaled.squeeze())\n",
    "    \n",
    "    inds_fl, vals_fl = create_update(x, y,\n",
    "                                     ts_fl[0], ts_fl[1],\n",
    "                                     p,\n",
    "                                     vol_size)\n",
    "    \n",
    "    volume.view(-1).put_(inds_fl, vals_fl, accumulate=True)\n",
    "    return volume\n",
    "\n",
    "def video_segment_to_voxel(video, t0, delta_t, bins):\n",
    "    current_time = video.current_time\n",
    "    video.seek_time(t0)\n",
    "    events = video.load_delta_t(delta_t)\n",
    "    video.seek_time(current_time)\n",
    "    return events_to_voxel(events, 5, *video.get_size())\n",
    "print(video.current_time)\n",
    "voxel = video_segment_to_voxel(video, 1000, delta_t=50000, bins=5)\n",
    "print(video.current_time)\n",
    "# https://github.com/alexzzhu/EventGAN/blob/c4230482509466741381b2d438cca1d16b497a1b/EventGAN/utils/event_utils.py#L77\n",
    "events = video.load_delta_t(50000)\n",
    "print(voxel.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "465f1896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57 250\n",
      "59.928757\n",
      "59.999999\n",
      "1 [[240 304]]\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "times = set()\n",
    "sizes = set()\n",
    "dats = glob.glob(op.join(settings['automotive_path'],\"train_a\",\"*.dat\"))\n",
    "for path in dats:\n",
    "    video = PSEELoader(path)\n",
    "    times.add(video.total_time())\n",
    "    sizes.add(tuple(video.get_size()))\n",
    "times = np.array(list(times))\n",
    "sizes= np.array(list(sizes))\n",
    "print(len(times), len(dats))\n",
    "print(us_to_s(times.min()))\n",
    "print(us_to_s(times.max()))\n",
    "int(us_to_ms(times.min())/50)\n",
    "print(len(sizes),sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a528e1c8",
   "metadata": {},
   "source": [
    "Assume we want int(us_to_ms(times.min())/50) voxels and bounding boxes for each voxel\n",
    "dtype=[('t', '<u8'), ('x', '<f4'), ('y', '<f4'), ('w', '<f4'), ('h', '<f4'), ('class_id', 'u1'), ('class_confidence', '<f4'), ('track_id', '<u4')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6e66fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dcb14601",
   "metadata": {},
   "source": [
    "# Bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "871855b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "video = PSEELoader(op.join(settings['automotive_path'],\"train_a\",\"17-03-30_12-53-58_1098500000_1158500000_td.dat\"))\n",
    "bboxes = PSEELoader(video._file.name.replace(\"_td.dat\",\"_bbox.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005de446",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bboxes = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37dcad4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(4099999, 162., 140., 40., 18., 0, 1., 1550)]\n",
      "[(5099999, 91., 134., 43., 22., 0, 1., 1551)]\n",
      "[(6099999,  13., 132., 51., 26., 0, 1., 1552)\n",
      " (6099999, 133., 137., 26., 17., 0, 1., 1553)]\n",
      "[(7099999, 23., 131., 41., 23., 0, 1., 1554)\n",
      " (7099999, 60., 133., 29., 19., 0, 1., 1555)]\n",
      "[(8099999,  14., 134., 35., 26., 0, 1., 1556)\n",
      " (8099999, -13., 134., 34., 28., 0, 1., 1557)]\n",
      "[(10099999, 58., 134., 29., 17., 0, 1., 1558)\n",
      " (10099999, 29., 133., 39., 21., 0, 1., 1559)]\n",
      "[(11099999, -6., 140., 51., 26., 0, 1., 1560)]\n",
      "[(14099999, 109., 133., 30., 18., 0, 1., 1561)]\n",
      "[(15099999, 65., 129., 36., 23., 0, 1., 1562)]\n",
      "[(16099999, -7., 123., 53., 33., 0, 1., 1563)]\n",
      "[(17099999, 289., 134., 14., 40., 1, 1., 1564)\n",
      " (17099999, -12., 144., 41., 18., 0, 1., 1565)]\n",
      "[(51099999, -17., 132., 106., 88., 0, 1., 1566)]\n",
      "[(52099999, -17., 128., 116., 87., 0, 1., 1567)]\n",
      "[(53099999, -4., 129., 111., 70., 0, 1., 1568)]\n",
      "[(54099999, 38., 135., 76., 53., 0, 1., 1569)]\n",
      "[(55099999, 65., 139., 57., 39., 0, 1., 1570)]\n",
      "[(56099999, 86., 139., 45., 31., 0, 1., 1571)\n",
      " (56099999, 28., 139., 38., 20., 0, 1., 1572)]\n",
      "[(57099999, 99., 139., 35., 28., 0, 1., 1573)\n",
      " (57099999, 26., 135., 41., 25., 0, 1., 1574)]\n",
      "[(58099999, 107., 141., 31., 23., 0, 1., 1575)\n",
      " (58099999,  47., 130., 13., 41., 1, 1., 1576)\n",
      " (58099999, 249., 139., 60., 23., 0, 1., 1577)]\n",
      "[(59099999, 110., 140., 24., 19., 0, 1., 1578)\n",
      " (59099999, 243., 132., 78., 26., 0, 1., 1579)]\n"
     ]
    }
   ],
   "source": [
    "bboxes.seek_time(0)\n",
    "while not bboxes.done: \n",
    "    gt = bboxes.load_delta_t(50000)\n",
    "    if gt.size:\n",
    "        print(gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9df282f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bboxes.seek_time(0)\n",
    "gt = bboxes.load_delta_t(50000)\n",
    "gt['x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db3461b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this functions can be used to read a video backwards for instance\n",
    "video.seek_time(video.total_time()+1)\n",
    "delta_t = 100000\n",
    "for t in np.arange(video.total_time()- delta_t, -delta_t, -delta_t):\n",
    "    video.seek_time(t)\n",
    "    events = video.load_delta_t(delta_t)\n",
    "    # they should be sorted in descending timestamp order !\n",
    "    events = events[::-1]\n",
    "    # do some cunning computer vision here.\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09469018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7d1cff02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#video = PSEELoader(op.join(settings['automotive_path'],\"train_a\",\"17-03-30_12-53-58_1098500000_1158500000_td.dat\"))\n",
    "for split in (\"train_a\",\"val_a\"):\n",
    "    video_filepaths = glob.glob((op.join(settings['automotive_path'],split, \"*.dat\")))\n",
    "    lines = []\n",
    "    for video_filepath in video_filepaths:\n",
    "        anno_filepath = video_filepath.replace(\"_td.dat\", \"_bbox.npy\")\n",
    "        assert op.exists(anno_filepath)\n",
    "        video = PSEELoader(video_filepath)\n",
    "        anno = PSEELoader(video_filepath)\n",
    "        assert video.total_time() == anno.total_time()\n",
    "        total_time = video.total_time()\n",
    "        line = f\"{video_filepath},{anno_filepath},{total_time}\\n\"\n",
    "        lines.append(line)\n",
    "    with open(f\"{split}.csv\", \"w\") as f:\n",
    "        f.writelines(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bf224dbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/tmp2/igor/EV/Dataset/Automotive/train_a/17-04-06_09-57-37_2806500000_2866500000_td.dat,/tmp2/igor/EV/Dataset/Automotive/train_a/17-04-06_09-57-37_2806500000_2866500000_bbox.npy,59999998\\n'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3873c4de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
